{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\ckkok\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Importing necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.metrics.pairwise import linear_kernel\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "import re\n",
    "import string\n",
    "import random\n",
    "from PIL import Image\n",
    "import requests\n",
    "from io import BytesIO\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.models.phrases import Phrases, Phraser\n",
    "from matplotlib import pyplot\n",
    "from gensim.models import KeyedVectors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading the data\n",
    "code_df = pd.read_csv(\"../../data/anime_codes.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>code</th>\n",
       "      <th>name</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5114</td>\n",
       "      <td>fullmetal_alchemist__brotherhood</td>\n",
       "      <td>9.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11061</td>\n",
       "      <td>hunter_x_hunter_2011</td>\n",
       "      <td>9.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28977</td>\n",
       "      <td>gintama°</td>\n",
       "      <td>9.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9969</td>\n",
       "      <td>gintama</td>\n",
       "      <td>9.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>38524</td>\n",
       "      <td>shingeki_no_kyojin_season_3_part_2</td>\n",
       "      <td>9.07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    code                                name  rating\n",
       "0   5114    fullmetal_alchemist__brotherhood    9.22\n",
       "1  11061                hunter_x_hunter_2011    9.12\n",
       "2  28977                            gintama°    9.11\n",
       "3   9969                             gintama    9.09\n",
       "4  38524  shingeki_no_kyojin_season_3_part_2    9.07"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "code_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(877, 2)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the review data\n",
    "reviews_dir = \"../../data/reviews\"\n",
    "all_reviews = list()\n",
    "\n",
    "for index, review_doc in enumerate(os.listdir(reviews_dir)):\n",
    "    current_dict = dict()\n",
    "        \n",
    "    # Get the current anime's code\n",
    "    current_dict['code'] = review_doc.split('.')[0]\n",
    "    \n",
    "    # Get the current anime's reviews\n",
    "    f = open(os.path.join(reviews_dir, review_doc), 'r', encoding=\"utf-8\")\n",
    "    current_dict['review'] = f.read()\n",
    "    f.close()\n",
    "    \n",
    "    all_reviews.append(current_dict)\n",
    "\n",
    "# Create a dataframe of the anime codes and their respective reviews\n",
    "review_df = pd.DataFrame(all_reviews)\n",
    "review_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(877, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>code</th>\n",
       "      <th>review</th>\n",
       "      <th>name</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>People who know me know that I'm not a fan of ...</td>\n",
       "      <td>cowboy_bebop</td>\n",
       "      <td>8.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1000</td>\n",
       "      <td>There is a reason this is considered to be one...</td>\n",
       "      <td>uchuu_kaizoku_captain_herlock</td>\n",
       "      <td>7.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1002</td>\n",
       "      <td>Many people will know the name of Hideaki Anno...</td>\n",
       "      <td>top_wo_nerae_2_diebuster</td>\n",
       "      <td>7.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10033</td>\n",
       "      <td>\"Cooking is as masculine as judo, kickboxing o...</td>\n",
       "      <td>toriko</td>\n",
       "      <td>7.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10049</td>\n",
       "      <td>After finishing the first series of Nurarihyon...</td>\n",
       "      <td>nurarihyon_no_mago__sennen_makyou</td>\n",
       "      <td>8.02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    code                                             review  \\\n",
       "0      1  People who know me know that I'm not a fan of ...   \n",
       "1   1000  There is a reason this is considered to be one...   \n",
       "2   1002  Many people will know the name of Hideaki Anno...   \n",
       "3  10033  \"Cooking is as masculine as judo, kickboxing o...   \n",
       "4  10049  After finishing the first series of Nurarihyon...   \n",
       "\n",
       "                                name  rating  \n",
       "0                       cowboy_bebop    8.79  \n",
       "1      uchuu_kaizoku_captain_herlock    7.72  \n",
       "2           top_wo_nerae_2_diebuster    7.68  \n",
       "3                             toriko    7.59  \n",
       "4  nurarihyon_no_mago__sennen_makyou    8.02  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Match the name and rating of animes in code_df to the anime reviews dataframe\n",
    "review_df['code']=review_df['code'].astype(int)\n",
    "df = pd.merge(review_df, code_df, on='code')\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning The Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Utitlity functions for removing ASCII characters, converting lower case, removing stop words, html and punctuation from description\n",
    "\n",
    "def _removeNonAscii(s):\n",
    "    return \"\".join(i for i in s if  ord(i)<128)\n",
    "\n",
    "def make_lower_case(text):\n",
    "    return text.lower()\n",
    "\n",
    "def remove_stop_words(text):\n",
    "    text = text.split()\n",
    "    stops = set(stopwords.words(\"english\"))\n",
    "    text = [w for w in text if not w in stops]\n",
    "    text = \" \".join(text)\n",
    "    return text\n",
    "\n",
    "def remove_html(text):\n",
    "    html_pattern = re.compile('<.*?>')\n",
    "    return html_pattern.sub(r'', text)\n",
    "\n",
    "def remove_punctuation(text):\n",
    "    tokenizer = RegexpTokenizer(r'\\w+')\n",
    "    text = tokenizer.tokenize(text)\n",
    "    text = \" \".join(text)\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>code</th>\n",
       "      <th>review</th>\n",
       "      <th>name</th>\n",
       "      <th>rating</th>\n",
       "      <th>cleaned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>People who know me know that I'm not a fan of ...</td>\n",
       "      <td>cowboy_bebop</td>\n",
       "      <td>8.79</td>\n",
       "      <td>people know know i m fan episodic anime series...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1000</td>\n",
       "      <td>There is a reason this is considered to be one...</td>\n",
       "      <td>uchuu_kaizoku_captain_herlock</td>\n",
       "      <td>7.72</td>\n",
       "      <td>reason considered one greatest anime series ev...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1002</td>\n",
       "      <td>Many people will know the name of Hideaki Anno...</td>\n",
       "      <td>top_wo_nerae_2_diebuster</td>\n",
       "      <td>7.68</td>\n",
       "      <td>many people know name hideaki anno particular ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10033</td>\n",
       "      <td>\"Cooking is as masculine as judo, kickboxing o...</td>\n",
       "      <td>toriko</td>\n",
       "      <td>7.59</td>\n",
       "      <td>cooking masculine judo kickboxing tae kwan do ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10049</td>\n",
       "      <td>After finishing the first series of Nurarihyon...</td>\n",
       "      <td>nurarihyon_no_mago__sennen_makyou</td>\n",
       "      <td>8.02</td>\n",
       "      <td>finishing first series nurarihyon mago bit rel...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    code                                             review  \\\n",
       "0      1  People who know me know that I'm not a fan of ...   \n",
       "1   1000  There is a reason this is considered to be one...   \n",
       "2   1002  Many people will know the name of Hideaki Anno...   \n",
       "3  10033  \"Cooking is as masculine as judo, kickboxing o...   \n",
       "4  10049  After finishing the first series of Nurarihyon...   \n",
       "\n",
       "                                name  rating  \\\n",
       "0                       cowboy_bebop    8.79   \n",
       "1      uchuu_kaizoku_captain_herlock    7.72   \n",
       "2           top_wo_nerae_2_diebuster    7.68   \n",
       "3                             toriko    7.59   \n",
       "4  nurarihyon_no_mago__sennen_makyou    8.02   \n",
       "\n",
       "                                             cleaned  \n",
       "0  people know know i m fan episodic anime series...  \n",
       "1  reason considered one greatest anime series ev...  \n",
       "2  many people know name hideaki anno particular ...  \n",
       "3  cooking masculine judo kickboxing tae kwan do ...  \n",
       "4  finishing first series nurarihyon mago bit rel...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['cleaned'] = df['review'].apply(_removeNonAscii)\n",
    "df['cleaned'] = df.cleaned.apply(func = make_lower_case)\n",
    "df['cleaned'] = df.cleaned.apply(func = remove_stop_words)\n",
    "df['cleaned'] = df.cleaned.apply(func=remove_punctuation)\n",
    "df['cleaned'] = df.cleaned.apply(func=remove_html)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applying Average Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#splitting the description into words\n",
    "\n",
    "corpus = []\n",
    "for words in df['cleaned']:\n",
    "    corpus.append(words.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 0)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using the Google pretrained Word2Vec Model (from: https://s3.amazonaws.com/dl4j-distribution/GoogleNews-vectors-negative300.bin.gz)\n",
    "\n",
    "EMBEDDING_FILE = '../../data/GoogleNews-vectors-negative300.bin.gz'\n",
    "google_word2vec = KeyedVectors.load_word2vec_format(EMBEDDING_FILE, binary=True)\n",
    "\n",
    "# Training our corpus with Google Pretrained Model\n",
    "\n",
    "google_model = Word2Vec(size = 300, window=5, min_count = 2, workers = -1)\n",
    "google_model.build_vocab(corpus)\n",
    "\n",
    "#model.intersect_word2vec_format('./word2vec/GoogleNews-vectors-negative300.bin', lockf=1.0, binary=True)\n",
    "\n",
    "google_model.intersect_word2vec_format(EMBEDDING_FILE, lockf=1.0, binary=True)\n",
    "\n",
    "google_model.train(corpus, total_examples=google_model.corpus_count, epochs = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ckkok\\Anaconda3\\envs\\animerec\\lib\\site-packages\\ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('attacks', 0.7638030052185059),\n",
       " ('assault', 0.5970098376274109),\n",
       " ('bombing', 0.5777696371078491),\n",
       " ('assaults', 0.5646902322769165),\n",
       " ('attacking', 0.5615357160568237),\n",
       " ('attacked', 0.5553597211837769),\n",
       " ('counterattack', 0.5205312371253967),\n",
       " ('ambush', 0.5107647180557251),\n",
       " ('raid', 0.502953290939331),\n",
       " ('blasts', 0.49935752153396606)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "google_model.most_similar('attack')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the average word2vec for the each set of anime reviews\n",
    "\n",
    "def vectors(x):\n",
    "    \n",
    "    # Creating a list for storing the vectors (description into vectors)\n",
    "    global array_embeddings\n",
    "    array_embeddings = []\n",
    "\n",
    "    # Reading the each anime review set\n",
    "    for line in df['cleaned']:\n",
    "        avgword2vec = None\n",
    "        count = 0\n",
    "        for word in line.split():\n",
    "            if word in google_model.wv.vocab:\n",
    "                count += 1\n",
    "                if avgword2vec is None:\n",
    "                    avgword2vec = google_model[word]\n",
    "                else:\n",
    "                    avgword2vec = avgword2vec + google_model[word]\n",
    "                \n",
    "        if avgword2vec is not None:\n",
    "            avgword2vec = avgword2vec / count\n",
    "        \n",
    "            array_embeddings.append(avgword2vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ckkok\\Anaconda3\\envs\\animerec\\lib\\site-packages\\ipykernel_launcher.py:17: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "C:\\Users\\ckkok\\Anaconda3\\envs\\animerec\\lib\\site-packages\\ipykernel_launcher.py:19: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n"
     ]
    }
   ],
   "source": [
    "# Calling the function vectors\n",
    "\n",
    "vectors(df)\n",
    "\n",
    "# finding cosine similarity for the vectors\n",
    "\n",
    "cosine_similarities = cosine_similarity(array_embeddings, array_embeddings)\n",
    "\n",
    "# taking the title and rating to store in new data frame called animes\n",
    "animes = df[['name', 'rating']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reverse mapping of the index\n",
    "indices = pd.Series(df.index, index = df['name']).drop_duplicates()# Recommending the Top 5 similar animes\n",
    "# drop all duplicate occurrences of the labels \n",
    "indices = indices.groupby(indices.index).first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommendations(title):\n",
    "         \n",
    "    idx = indices[title]\n",
    "    sim_scores = sorted(list(enumerate(cosine_similarities[idx])), key = lambda x: x[1], reverse = True)\n",
    "    sim_scores = sim_scores[1:6]\n",
    "    anime_indices = [i[0] for i in sim_scores]\n",
    "    recommend = animes.iloc[anime_indices]\n",
    "    \n",
    "    count = 0\n",
    "    for index, row in recommend.iterrows():\n",
    "        print('{}. {}, similarity: {}, rating: {}'.format(count+1, row['name'], sim_scores[count][1], row['rating']))\n",
    "        count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. michiko_to_hatchin, similarity: 0.9917200803756714, rating: 7.85\n",
      "2. cowboy_bebop__tengoku_no_tobira, similarity: 0.9910752773284912, rating: 8.39\n",
      "3. trigun, similarity: 0.9908796548843384, rating: 8.24\n",
      "4. baccano, similarity: 0.9905235171318054, rating: 8.42\n",
      "5. samurai_champloo, similarity: 0.9898200631141663, rating: 8.5\n"
     ]
    }
   ],
   "source": [
    "recommendations('cowboy_bebop')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applying TF-IDF Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Building TFIDF model and calculate TFIDF score\n",
    "\n",
    "tfidf = TfidfVectorizer(analyzer='word', ngram_range=(1, 3), min_df = 5, stop_words='english')\n",
    "tfidf.fit(df['cleaned'])\n",
    "\n",
    "# Getting the words from the TF-IDF model\n",
    "\n",
    "tfidf_list = dict(zip(tfidf.get_feature_names(), list(tfidf.idf_)))\n",
    "tfidf_feature = tfidf.get_feature_names() # tfidf words/col-names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading: 0/877\n",
      "loading: 1/877\n",
      "loading: 2/877\n",
      "loading: 3/877\n",
      "loading: 4/877\n",
      "loading: 5/877\n",
      "loading: 6/877\n",
      "loading: 7/877\n",
      "loading: 8/877\n",
      "loading: 9/877\n",
      "loading: 10/877\n",
      "loading: 11/877\n",
      "loading: 12/877\n",
      "loading: 13/877\n",
      "loading: 14/877\n",
      "loading: 15/877\n",
      "loading: 16/877\n",
      "loading: 17/877\n",
      "loading: 18/877\n",
      "loading: 19/877\n",
      "loading: 20/877\n",
      "loading: 21/877\n",
      "loading: 22/877\n",
      "loading: 23/877\n",
      "loading: 24/877\n",
      "loading: 25/877\n",
      "loading: 26/877\n",
      "loading: 27/877\n",
      "loading: 28/877\n",
      "loading: 29/877\n",
      "loading: 30/877\n",
      "loading: 31/877\n",
      "loading: 32/877\n",
      "loading: 33/877\n",
      "loading: 34/877\n",
      "loading: 35/877\n",
      "loading: 36/877\n",
      "loading: 37/877\n",
      "loading: 38/877\n",
      "loading: 39/877\n",
      "loading: 40/877\n",
      "loading: 41/877\n",
      "loading: 42/877\n",
      "loading: 43/877\n",
      "loading: 44/877\n",
      "loading: 45/877\n",
      "loading: 46/877\n",
      "loading: 47/877\n",
      "loading: 48/877\n",
      "loading: 49/877\n",
      "loading: 50/877\n",
      "loading: 51/877\n",
      "loading: 52/877\n",
      "loading: 53/877\n",
      "loading: 54/877\n",
      "loading: 55/877\n",
      "loading: 56/877\n",
      "loading: 57/877\n",
      "loading: 58/877\n",
      "loading: 59/877\n",
      "loading: 60/877\n",
      "loading: 61/877\n",
      "loading: 62/877\n",
      "loading: 63/877\n",
      "loading: 64/877\n",
      "loading: 65/877\n",
      "loading: 66/877\n",
      "loading: 67/877\n",
      "loading: 68/877\n",
      "loading: 69/877\n",
      "loading: 70/877\n",
      "loading: 71/877\n",
      "loading: 72/877\n",
      "loading: 73/877\n",
      "loading: 74/877\n",
      "loading: 75/877\n",
      "loading: 76/877\n",
      "loading: 77/877\n",
      "loading: 78/877\n",
      "loading: 79/877\n",
      "loading: 80/877\n",
      "loading: 81/877\n",
      "loading: 82/877\n",
      "loading: 83/877\n",
      "loading: 84/877\n",
      "loading: 85/877\n",
      "loading: 86/877\n",
      "loading: 87/877\n",
      "loading: 88/877\n",
      "loading: 89/877\n",
      "loading: 90/877\n",
      "loading: 91/877\n",
      "loading: 92/877\n",
      "loading: 93/877\n",
      "loading: 94/877\n",
      "loading: 95/877\n",
      "loading: 96/877\n",
      "loading: 97/877\n",
      "loading: 98/877\n",
      "loading: 99/877\n",
      "loading: 100/877\n",
      "loading: 101/877\n",
      "loading: 102/877\n",
      "loading: 103/877\n",
      "loading: 104/877\n",
      "loading: 105/877\n",
      "loading: 106/877\n",
      "loading: 107/877\n",
      "loading: 108/877\n",
      "loading: 109/877\n",
      "loading: 110/877\n",
      "loading: 111/877\n",
      "loading: 112/877\n",
      "loading: 113/877\n",
      "loading: 114/877\n",
      "loading: 115/877\n",
      "loading: 116/877\n",
      "loading: 117/877\n",
      "loading: 118/877\n",
      "loading: 119/877\n",
      "loading: 120/877\n",
      "loading: 121/877\n",
      "loading: 122/877\n",
      "loading: 123/877\n",
      "loading: 124/877\n",
      "loading: 125/877\n",
      "loading: 126/877\n",
      "loading: 127/877\n",
      "loading: 128/877\n",
      "loading: 129/877\n",
      "loading: 130/877\n",
      "loading: 131/877\n",
      "loading: 132/877\n",
      "loading: 133/877\n",
      "loading: 134/877\n",
      "loading: 135/877\n",
      "loading: 136/877\n",
      "loading: 137/877\n",
      "loading: 138/877\n",
      "loading: 139/877\n",
      "loading: 140/877\n",
      "loading: 141/877\n",
      "loading: 142/877\n",
      "loading: 143/877\n",
      "loading: 144/877\n",
      "loading: 145/877\n",
      "loading: 146/877\n",
      "loading: 147/877\n",
      "loading: 148/877\n",
      "loading: 149/877\n",
      "loading: 150/877\n",
      "loading: 151/877\n",
      "loading: 152/877\n",
      "loading: 153/877\n",
      "loading: 154/877\n",
      "loading: 155/877\n",
      "loading: 156/877\n",
      "loading: 157/877\n",
      "loading: 158/877\n",
      "loading: 159/877\n",
      "loading: 160/877\n",
      "loading: 161/877\n",
      "loading: 162/877\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-27-1f80d0bf46e1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[0mweight_sum\u001b[0m \u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m;\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[1;31m# for each word in the anime reviews\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdesc\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mword\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mgoogle_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvocab\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mword\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtfidf_feature\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m             \u001b[0mvec\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgoogle_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwv\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# # Building TF-IDF Word2Vec \n",
    "\n",
    "# # Storing the TFIDF Word2Vec embeddings\n",
    "# tfidf_vectors = []; \n",
    "# line = 0;\n",
    "\n",
    "# # for each anime's set of reviews\n",
    "# for desc in corpus: \n",
    "#     print('loading: {}/{}'.format(line, len(corpus)))\n",
    "#     # Word vectors are of zero length (Used 300 dimensions)\n",
    "#     sent_vec = np.zeros(300) \n",
    "#     # num of words with a valid vector in the anime reviews\n",
    "#     weight_sum =0; \n",
    "#     # for each word in the anime reviews\n",
    "#     for word in desc: \n",
    "#         if word in google_model.wv.vocab and word in tfidf_feature:\n",
    "#             vec = google_model.wv[word]\n",
    "#             tf_idf = tfidf_list[word] * (desc.count(word) / len(desc))\n",
    "#             sent_vec += (vec * tf_idf)\n",
    "#             weight_sum += tf_idf\n",
    "#     if weight_sum != 0:\n",
    "#         sent_vec /= weight_sum\n",
    "#     tfidf_vectors.append(sent_vec)\n",
    "#     line += 1\n",
    "\n",
    "# # Save file cause it's a really long process to build all the embeddings\n",
    "# with open('tfidf_vectors.data', 'wb') as filehandle:\n",
    "#     # store the data as binary data stream\n",
    "#     pickle.dump(tfidf_vectors, filehandle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('tfidf_vectors.data', 'rb') as filehandle:\n",
    "    # read the data as binary data stream\n",
    "    tfidf_vectors = pickle.load(filehandle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Recommending top 5 similar animes\n",
    "\n",
    "def recommendations(title):\n",
    "    \n",
    "    # finding cosine similarity for the vectors\n",
    "\n",
    "    cosine_similarities = cosine_similarity(tfidf_vectors,  tfidf_vectors)\n",
    "    \n",
    "    animes = df[['name', 'rating']]\n",
    "    #Reverse mapping of the index\n",
    "    indices = pd.Series(df.index, index = df['name']).drop_duplicates()\n",
    "    # drop all duplicate occurrences of the labels \n",
    "    indices = indices.groupby(indices.index).first()\n",
    "         \n",
    "    idx = indices[title]\n",
    "    sim_scores = list(enumerate(cosine_similarities[idx]))\n",
    "    sim_scores = sorted(sim_scores, key = lambda x: x[1], reverse = True)\n",
    "    sim_scores = sim_scores[1:6]\n",
    "    anime_indices = [i[0] for i in sim_scores]\n",
    "    recommend = animes.iloc[anime_indices]\n",
    "    \n",
    "    count = 0\n",
    "    for index, row in recommend.iterrows():\n",
    "        print('{}. {}, similarity: {}, rating: {}'.format(count+1, row['name'], sim_scores[count][1], row['rating']))\n",
    "        count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. naruto__shippuuden_movie_6_-_road_to_ninja, similarity: 0.9334548115853434, rating: 7.69\n",
      "2. mobile_suit_gundam_iii__encounters_in_space, similarity: 0.8377889660557561, rating: 7.77\n",
      "3. rakuen_tsuihou, similarity: 0.8292637521261761, rating: 7.41\n",
      "4. hakuouki_movie_1__kyoto_ranbu, similarity: 0.8042539994639673, rating: 7.69\n",
      "5. gintama_movie_2__kanketsu-hen_-_yorozuya_yo_eien_nare, similarity: 0.801945827099659, rating: 8.97\n"
     ]
    }
   ],
   "source": [
    "recommendations('naruto__shippuuden_movie_5_-_blood_prison')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cowboy_bebop</td>\n",
       "      <td>8.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>uchuu_kaizoku_captain_herlock</td>\n",
       "      <td>7.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>top_wo_nerae_2_diebuster</td>\n",
       "      <td>7.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>toriko</td>\n",
       "      <td>7.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>nurarihyon_no_mago__sennen_makyou</td>\n",
       "      <td>8.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>tenchi_muyou_in_love</td>\n",
       "      <td>7.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>fate_zero</td>\n",
       "      <td>8.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>break_blade_6__doukoku_no_toride</td>\n",
       "      <td>7.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ranma_½__chou_musabetsu_kessen_ranma_team_vs_d...</td>\n",
       "      <td>7.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>mahou_shoujo_lyrical_nanoha__the_movie_2nd_as</td>\n",
       "      <td>8.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>no6</td>\n",
       "      <td>7.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>c__the_money_of_soul_and_possibility_control</td>\n",
       "      <td>7.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>berserk__ougon_jidai-hen_i_-_haou_no_tamago</td>\n",
       "      <td>7.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>towa_no_quon_1__utakata_no_kaben</td>\n",
       "      <td>7.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>sennen_joyuu</td>\n",
       "      <td>8.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>ouritsu_uchuugun__honneamise_no_tsubasa</td>\n",
       "      <td>7.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>hakuouki_sekkaroku</td>\n",
       "      <td>7.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>ben-to</td>\n",
       "      <td>7.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>sengoku_basara_two__ryuko_itadaki_no_chikai_at...</td>\n",
       "      <td>7.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>naruto__shippuuden_movie_5_-_blood_prison</td>\n",
       "      <td>7.48</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 name  rating\n",
       "0                                        cowboy_bebop    8.79\n",
       "1                       uchuu_kaizoku_captain_herlock    7.72\n",
       "2                            top_wo_nerae_2_diebuster    7.68\n",
       "3                                              toriko    7.59\n",
       "4                   nurarihyon_no_mago__sennen_makyou    8.02\n",
       "5                                tenchi_muyou_in_love    7.44\n",
       "6                                           fate_zero    8.36\n",
       "7                    break_blade_6__doukoku_no_toride    7.72\n",
       "8   ranma_½__chou_musabetsu_kessen_ranma_team_vs_d...    7.39\n",
       "9       mahou_shoujo_lyrical_nanoha__the_movie_2nd_as    8.19\n",
       "10                                                no6    7.59\n",
       "11       c__the_money_of_soul_and_possibility_control    7.27\n",
       "12        berserk__ougon_jidai-hen_i_-_haou_no_tamago    7.78\n",
       "13                   towa_no_quon_1__utakata_no_kaben    7.39\n",
       "14                                       sennen_joyuu    8.28\n",
       "15            ouritsu_uchuugun__honneamise_no_tsubasa    7.54\n",
       "16                                 hakuouki_sekkaroku    7.67\n",
       "17                                             ben-to    7.31\n",
       "18  sengoku_basara_two__ryuko_itadaki_no_chikai_at...    7.27\n",
       "19          naruto__shippuuden_movie_5_-_blood_prison    7.48"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "animes.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
